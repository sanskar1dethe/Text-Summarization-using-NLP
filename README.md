## End-to-End Text Summarization using NLP & Transformers

An end-to-end abstractive text summarization system built using Transformer-based models (PEGASUS).
This project demonstrates a complete production-grade ML workflow including modular pipeline design, Docker containerization, CI/CD automation, and AWS deployment.

Focus: Not just model training â€” but building a deployable, scalable ML system.



### ğŸš€ Project Overview

This project implements a full machine learning pipeline that:

Ingests and preprocesses text data

Fine-tunes a Transformer model for summarization

Evaluates model performance

Exposes predictions via a FastAPI REST API

Containerizes the application using Docker

Automates CI/CD using GitHub Actions

Deploys on AWS EC2 using Amazon ECR




### ğŸ§  Model Architecture
PEGASUS (Encoderâ€“Decoder Transformer)

Built using Hugging Face Transformers

Designed for abstractive text summarization

Trained using cross-entropy loss for next-token prediction

Encoderâ€“Decoder Intuition

Encoder â†’ Converts input text into contextual embeddings

Decoder â†’ Generates summary based on encoded meaning

The model learns to generate shorter, meaningful summaries while preserving context




### ğŸ—ï¸ Project Structure

Text-Summarization-using-NLP/
â”‚
â”œâ”€â”€ src/textSummarizer/
â”‚   â”œâ”€â”€ components/         # Data ingestion & model components
â”‚   â”œâ”€â”€ pipeline/           # Training & prediction pipelines
â”‚   â”œâ”€â”€ config/             # Configuration management
â”‚   â”œâ”€â”€ utils/              # Utility functions
â”‚
â”œâ”€â”€ artifacts/              # Model artifacts (ignored in Git)
â”œâ”€â”€ app.py                  # FastAPI application
â”œâ”€â”€ Dockerfile              # Docker configuration
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .github/workflows/      # CI/CD pipeline
â””â”€â”€ README.md




### âš™ï¸ Features

âœ” Modular ML pipeline
âœ” Configuration-driven design
âœ” Transformer-based summarization
âœ” FastAPI inference endpoint
âœ” Dockerized deployment
âœ” GitHub Actions CI/CD
âœ” AWS ECR integration
âœ” EC2 self-hosted deployment




### ğŸ” CI/CD Workflow
Continuous Integration

Triggered on push to main:

Checkout code

Lint checks

Unit tests

Continuous Delivery

Build Docker image

Tag and push image to Amazon ECR

Continuous Deployment

Self-hosted GitHub runner on EC2

Pull latest image

Run container on port 8080

Cleanup old images




### ğŸ³ Docker Usage
Build Image
docker build -t text-summarizer .

Run Container
docker run -p 8080:8080 text-summarizer


Access API at:

http://localhost:8080

â˜ï¸ AWS Deployment

The project uses:

Amazon ECR â†’ Container registry

Amazon EC2 â†’ Hosting environment

GitHub Self-Hosted Runner â†’ Automated deployment

IAM Credentials â†’ Secure AWS authentication

Deployment is fully automated through GitHub Actions.




### ğŸ“Š Tech Stack

Python

Hugging Face Transformers

PyTorch

FastAPI

Docker

GitHub Actions

AWS (ECR, EC2)

YAML-based configuration



### ğŸ§ª Run Locally
git clone https://github.com/sanskar1dethe/Text-Summarization-using-NLP.git
cd Text-Summarization-using-NLP
pip install -r requirements.txt
python app.py




### ğŸ“ˆ Key Learnings

Transformer Encoderâ€“Decoder architecture

Building modular ML pipelines

Docker optimization and debugging

CI/CD automation

AWS container deployment

Managing ML dependencies in production

ğŸ‘¤ Author

Sanskar Dethe
B.Tech Mathematics & Computing | IIT Goa
AI Engineer | NLP | MLOps | Production ML Systems



# END TO END Text-Summarization-using-NLP

# Workflow 

1. Update config.yaml 
2. Update params.yaml
3. Update entities.yaml
4. Update the configuration manager in src config
5. Update the components
6. Update the pipeline 
7. Update main.py
8. Update app.py

